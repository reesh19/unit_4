{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "declared-bulgaria",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:27:16.929206Z",
     "start_time": "2021-03-14T23:27:13.990333Z"
    },
    "code_folding": [
     0
    ],
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/reesh/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, mean_absolute_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from xgboost import XGBRFClassifier, XGBClassifier\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "returning-marijuana",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:27:17.025941Z",
     "start_time": "2021-03-14T23:27:16.932203Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# initial data\n",
    "df = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "micro-defendant",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:27:17.041458Z",
     "start_time": "2021-03-14T23:27:17.029963Z"
    },
    "code_folding": [
     0,
     1,
     28,
     46
    ],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "def lemmaz(doc):\n",
    "    lemmas = []\n",
    "    multi_ws = '[ ]{2,}'\n",
    "    non_alpha = '[^a-zA-Z]'\n",
    "    lonely = ' [a-zA-Z] '\n",
    "    empty_start = '^ '\n",
    "    empty_end = ' $'\n",
    "\n",
    "    doc = re.sub(non_alpha, ' ', doc)\n",
    "    doc = re.sub(lonely, ' ', doc)\n",
    "    doc = re.sub(multi_ws, ' ', doc)\n",
    "    doc = re.sub(empty_start, '', doc)\n",
    "    doc = re.sub(empty_end, '', doc)\n",
    "    doc = doc.lower()\n",
    "    \n",
    "    doc = nlp(doc)\n",
    "\n",
    "    for token in doc:\n",
    "        if (((token.pos_ == 'ADJ')\n",
    "             or (token.pos_ == 'NOUN')\n",
    "             or (token.pos_ == 'VERB'))\n",
    "            and (token.is_stop == False)):\n",
    "            lemmas.append(token.lemma_)\n",
    "\n",
    "    return lemmas\n",
    "\n",
    "\n",
    "def stringz(doc):\n",
    "    lemma_docs = []\n",
    "\n",
    "    lonely = ' [a-zA-Z] '\n",
    "    empty_start = '^ '\n",
    "    empty_end = ' $'\n",
    "    \n",
    "    for lemma_list in doc:\n",
    "        text = \"\"\n",
    "        for lemma in lemma_list:\n",
    "            text = \" \".join((text, lemma))        \n",
    "        text = re.sub(lonely, ' ', text)\n",
    "        text = re.sub(empty_start, '', text)\n",
    "        text = re.sub(empty_end, '', text) \n",
    "        lemma_docs.append(text)\n",
    "    return lemma_docs\n",
    "\n",
    "\n",
    "def vec(doc):\n",
    "    return [nlp(doc).vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "comparative-blake",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:30:03.257827Z",
     "start_time": "2021-03-14T23:27:17.045907Z"
    },
    "code_folding": [
     0,
     1
    ],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "def train_data_tranformer(df):\n",
    "    df['target'] = df.ratingCategory\n",
    "    df['lemmas'] = df.description.apply(lemmaz)\n",
    "    df[\"text\"] = stringz(df.lemmas)\n",
    "    df['vector'] = df.text.apply(vec)\n",
    "\n",
    "    # numerical\n",
    "    df[\"chars\"] = df.description.apply(lambda x: len(x))\n",
    "    df[\"words\"] = df.description.apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "    df[\"sentiments\"] = df.text.apply(lambda x: sid.polarity_scores(x))\n",
    "    df = pd.concat([df.drop(['sentiments'], axis=1), df['sentiments'].apply(pd.Series)], axis=1)\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_result = tfidf.fit_transform(df.text).toarray()\n",
    "    tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
    "    tfidf_df.columns = [\"w_\" + str(x) for x in tfidf_df.columns]\n",
    "    tfidf_df.index = df.index\n",
    "\n",
    "    df = pd.concat([df.drop(columns=['description','ratingCategory']), tfidf_df], axis=1)\n",
    "    return df\n",
    "\n",
    "df = train_data_tranformer(df)\n",
    "df.to_csv('train_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "involved-attribute",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:30:44.439956Z",
     "start_time": "2021-03-14T23:30:03.260035Z"
    }
   },
   "outputs": [],
   "source": [
    "train = df.drop(columns=['lemmas','id'])\n",
    "train.to_csv('train_ready.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "israeli-china",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:31:01.652726Z",
     "start_time": "2021-03-14T23:30:44.443289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>w_abandon</th>\n",
       "      <th>...</th>\n",
       "      <th>w_zinfandel</th>\n",
       "      <th>w_zing</th>\n",
       "      <th>w_zinge</th>\n",
       "      <th>w_zinginess</th>\n",
       "      <th>w_zingy</th>\n",
       "      <th>w_zip</th>\n",
       "      <th>w_zippy</th>\n",
       "      <th>w_zombie</th>\n",
       "      <th>w_zone</th>\n",
       "      <th>w_zuidam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>whisky batch leftover barrel return warehouse ...</td>\n",
       "      <td>[array([-6.12000078e-02,  2.31518507e-01, -7.4...</td>\n",
       "      <td>513</td>\n",
       "      <td>76</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>uncommon exclusive bottling year old cask stre...</td>\n",
       "      <td>[array([-3.20599135e-03,  1.96402133e-01, -1.1...</td>\n",
       "      <td>471</td>\n",
       "      <td>81</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>release port version amrut intermediate sherry...</td>\n",
       "      <td>[array([ 1.12371407e-01,  1.00963630e-01, -8.5...</td>\n",
       "      <td>482</td>\n",
       "      <td>84</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>year old single cask age sherry butt interact ...</td>\n",
       "      <td>[array([-1.21437453e-01,  2.08656073e-01, -9.2...</td>\n",
       "      <td>450</td>\n",
       "      <td>69</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>herbal nose aroma dry tarragon parsley dill ch...</td>\n",
       "      <td>[array([-1.42396763e-01,  2.51199961e-01, -1.7...</td>\n",
       "      <td>427</td>\n",
       "      <td>65</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8746 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       1  whisky batch leftover barrel return warehouse ...   \n",
       "1       0  uncommon exclusive bottling year old cask stre...   \n",
       "2       1  release port version amrut intermediate sherry...   \n",
       "3       1  year old single cask age sherry butt interact ...   \n",
       "4       1  herbal nose aroma dry tarragon parsley dill ch...   \n",
       "\n",
       "                                              vector  chars  words    neg  \\\n",
       "0  [array([-6.12000078e-02,  2.31518507e-01, -7.4...    513     76  0.097   \n",
       "1  [array([-3.20599135e-03,  1.96402133e-01, -1.1...    471     81  0.079   \n",
       "2  [array([ 1.12371407e-01,  1.00963630e-01, -8.5...    482     84  0.024   \n",
       "3  [array([-1.21437453e-01,  2.08656073e-01, -9.2...    450     69  0.000   \n",
       "4  [array([-1.42396763e-01,  2.51199961e-01, -1.7...    427     65  0.000   \n",
       "\n",
       "     neu    pos  compound  w_abandon  ...  w_zinfandel  w_zing  w_zinge  \\\n",
       "0  0.734  0.170    0.5859        0.0  ...          0.0     0.0      0.0   \n",
       "1  0.696  0.225    0.8020        0.0  ...          0.0     0.0      0.0   \n",
       "2  0.755  0.221    0.8658        0.0  ...          0.0     0.0      0.0   \n",
       "3  0.886  0.114    0.6486        0.0  ...          0.0     0.0      0.0   \n",
       "4  0.875  0.125    0.6486        0.0  ...          0.0     0.0      0.0   \n",
       "\n",
       "   w_zinginess  w_zingy  w_zip  w_zippy  w_zombie  w_zone  w_zuidam  \n",
       "0          0.0      0.0    0.0      0.0       0.0     0.0       0.0  \n",
       "1          0.0      0.0    0.0      0.0       0.0     0.0       0.0  \n",
       "2          0.0      0.0    0.0      0.0       0.0     0.0       0.0  \n",
       "3          0.0      0.0    0.0      0.0       0.0     0.0       0.0  \n",
       "4          0.0      0.0    0.0      0.0       0.0     0.0       0.0  \n",
       "\n",
       "[5 rows x 8746 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_ready.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "other-inspection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T22:58:47.852433Z",
     "start_time": "2021-03-14T22:58:47.638816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4087, 8743), (4087,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns=['target','vector','text'])\n",
    "y = train.target\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "diagnostic-jacob",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:19:34.569835Z",
     "start_time": "2021-03-14T23:19:34.559529Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4087, 8743)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, nlp):\n",
    "#         self.nlp = nlp\n",
    "#         self.dim = 300\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         return [self.nlp(doc).vector for doc in X]\n",
    "    \n",
    "# svd = TruncatedSVD()\n",
    "# xgb = XGBClassifier(random_state=19)\n",
    "# mms = MinMaxScaler()\n",
    "# pca = PCA()\n",
    "# ss = StandardScaler()\n",
    "\n",
    "\n",
    "# model = Pipeline([('clf', xgb)])\n",
    "\n",
    "# model = Pipeline([(\"lsa\", lsa),\n",
    "#                  (\"clf\", xgb)])\n",
    "\n",
    "# text_set = pipe.fit_transform(text_data)\n",
    "\n",
    "# pca = Pipeline([(\"minmaxscaler\", mms), \n",
    "#                 ('pca', pca)])\n",
    "\n",
    "# pipe_num = Pipeline([(\"standardscaler\", ss)])\n",
    "\n",
    "# transformer_list = [(\"pca\", pca), \n",
    "#                     (\"scaler\", pipe_num)]   \n",
    "\n",
    "# num_union = FeatureUnion(transformer_list, n_jobs=-1, verbose=2)\n",
    "# num_set = num_union.fit_transform(num_data)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "expected-fountain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:07:36.415944Z",
     "start_time": "2021-03-14T23:07:36.407153Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "obj = [ 'rank:ndcg' , 'rank:map', 'rank:pairwise' ]\n",
    "eta = np.arange( 0.01 , .1 , .005 ) \n",
    "mdepth = np.arange( 5 , 21 , 3 )\n",
    "ssam = np.arange( .5 , 1 , .05 )\n",
    "colsamp = np.arange( .5 , 1 , .05 )\n",
    "tmeth = [ 'gpu_hist' , 'approx' ]\n",
    "gpol = [ 'depthwise' , 'lossguide' ]\n",
    "est = np.arange( 200 , 401 , 20 )\n",
    "emet = [ 'merror', 'mlogloss', 'ndcg', 'map' ]\n",
    "lam = np.arange( 0 , 10 , 1 )\n",
    "alp = np.arange( 0 , 10 , 1 )\n",
    "\n",
    "params = {           #\"svd__n_components\": np.arange(100, 1001, 100),\n",
    "                     'clf__objective' : obj ,\n",
    "                           'clf__eta' : eta ,\n",
    "                     'clf__max_depth' : mdepth ,\n",
    "                     'clf__subsample' : ssam ,\n",
    "                   'clf__grow_policy' : gpol ,\n",
    "              'clf__colsample_bytree' : colsamp ,\n",
    "                  'clf__n_estimators' : est,\n",
    "                   'clf__tree_method' : tmeth ,               \n",
    "                   'clf__eval_metric' : emet ,\n",
    "                    'clf__reg_lambda' : lam ,\n",
    "                     'clf__reg_alpha' : alp,\n",
    "         }\n",
    "\n",
    "# params = {           'objective' : obj ,\n",
    "#                            'eta' : eta ,\n",
    "#                      'max_depth' : mdepth ,\n",
    "#                      'subsample' : ssam ,\n",
    "#                    'grow_policy' : gpol ,\n",
    "#               'colsample_bytree' : colsamp ,\n",
    "#                   'n_estimators' : est,\n",
    "#                    'tree_method' : tmeth ,               \n",
    "#                    'eval_metric' : emet ,\n",
    "#                     'reg_lambda' : lam ,\n",
    "#                      'reg_alpha' : alp,\n",
    "#          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sunrise-hunger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:19:23.856858Z",
     "start_time": "2021-03-14T23:07:48.243291Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-949286295e25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                           verbose=2)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mrscv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/Sprint_1-MFzck0uo/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Sprint_1-MFzck0uo/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Sprint_1-MFzck0uo/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[1;32m   1620\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m             random_state=self.random_state))\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Sprint_1-MFzck0uo/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Sprint_1-MFzck0uo/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Sprint_1-MFzck0uo/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Sprint_1-MFzck0uo/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD()\n",
    "xgb = XGBClassifier(random_state=19)\n",
    "\n",
    "pipe = Pipeline([('svd',svd),('clf', xgb)])\n",
    "\n",
    "rscv = RandomizedSearchCV(xgb, \n",
    "                          params, \n",
    "                          n_iter=3, \n",
    "                          n_jobs=-1, \n",
    "                          cv=2, \n",
    "                          verbose=2)\n",
    "\n",
    "rscv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-wichita",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:07:01.098409Z",
     "start_time": "2021-03-14T23:03:40.663Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print('MAE: ' , round( mean_absolute_error( y , rscv.predict( X ) ) , 3 ) )\n",
    "# print('Validation MAE: ' , round( mean_absolute_error( \n",
    "#                                y_test , rscv.predict( X_test ) ) , 3 ) )\n",
    "tuned_rscv = rscv.best_estimator_\n",
    "rscv.best_score_, rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "closing-organization",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T19:34:19.194285Z",
     "start_time": "2021-03-11T19:34:19.190022Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# best_score_ 5x3 = 0.734094616639478\n",
    "# best_score_ 100x5 = 0.7395223306713989\n",
    "                    # {'svd__n_components': 61,\n",
    "                    # 'clf__tree_method': 'approx',\n",
    "                    # 'clf__subsample': 0.8500000000000003,\n",
    "                    # 'clf__reg_lambda': 4,\n",
    "                    # 'clf__reg_alpha': 8,\n",
    "                    # 'clf__objective': 'rank:pairwise',\n",
    "                    # 'clf__n_estimators': 201,\n",
    "                    # 'clf__max_depth': 9,\n",
    "                    # 'clf__grow_policy': 'lossguide',\n",
    "                    # 'clf__eval_metric': 'map',\n",
    "                    # 'clf__eta': 0.1,\n",
    "                    # 'clf__colsample_bytree': 0.8000000000000003}\n",
    "                    \n",
    "# best_score_ 200x3 = 0.7400761283306144\n",
    "                    #  {'svd__n_components': 51,\n",
    "                    #   'clf__tree_method': 'approx',\n",
    "                    #   'clf__subsample': 0.6500000000000001,\n",
    "                    #   'clf__reg_lambda': 7,\n",
    "                    #   'clf__reg_alpha': 4,\n",
    "                    #   'clf__objective': 'rank:map',\n",
    "                    #   'clf__n_estimators': 201,\n",
    "                    #   'clf__max_depth': 17,\n",
    "                    #   'clf__grow_policy': 'depthwise',\n",
    "                    #   'clf__eval_metric': 'mlogloss',\n",
    "                    #   'clf__eta': 0.1,\n",
    "                    #   'clf__colsample_bytree': 0.8000000000000003}\n",
    "                    \n",
    "# best_score_ 400x3 = 0.744426318651441\n",
    "                    #  {'svd__n_components': 60,\n",
    "                    #   'clf__tree_method': 'approx',\n",
    "                    #   'clf__subsample': 0.8500000000000003,\n",
    "                    #   'clf__reg_lambda': 1,\n",
    "                    #   'clf__reg_alpha': 6,\n",
    "                    #   'clf__objective': 'rank:map',\n",
    "                    #   'clf__n_estimators': 340,\n",
    "                    #   'clf__max_depth': 13,\n",
    "                    #   'clf__grow_policy': 'lossguide',\n",
    "                    #   'clf__eval_metric': 'ndcg',\n",
    "                    #   'clf__eta': 0.06499999999999999,\n",
    "                    #   'clf__colsample_bytree': 0.6500000000000001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "turned-current",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T01:13:41.167247Z",
     "start_time": "2021-03-14T01:13:09.897130Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>w_abandon</th>\n",
       "      <th>w_abatement</th>\n",
       "      <th>w_abc</th>\n",
       "      <th>...</th>\n",
       "      <th>w_zealand</th>\n",
       "      <th>w_zeitgeist</th>\n",
       "      <th>w_zest</th>\n",
       "      <th>w_zested</th>\n",
       "      <th>w_zesty</th>\n",
       "      <th>w_zinfandel</th>\n",
       "      <th>w_zing</th>\n",
       "      <th>w_zingy</th>\n",
       "      <th>w_zip</th>\n",
       "      <th>w_zippy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.0976305, 0.15472263, -0.15228683, -0.00053...</td>\n",
       "      <td>409</td>\n",
       "      <td>64</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.090834245, 0.16909483, -0.0033552991, -0.0...</td>\n",
       "      <td>574</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.031802785, 0.12913445, -0.02464436, -0.062...</td>\n",
       "      <td>481</td>\n",
       "      <td>76</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.13696712, 0.10186601, -0.048041925, -0.154...</td>\n",
       "      <td>209</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.05216053, 0.14466654, -0.15954311, 0.104861...</td>\n",
       "      <td>357</td>\n",
       "      <td>60</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4742 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              vector  chars  words    neg  \\\n",
       "0  [-0.0976305, 0.15472263, -0.15228683, -0.00053...    409     64  0.057   \n",
       "1  [-0.090834245, 0.16909483, -0.0033552991, -0.0...    574     95  0.000   \n",
       "2  [-0.031802785, 0.12913445, -0.02464436, -0.062...    481     76  0.109   \n",
       "3  [-0.13696712, 0.10186601, -0.048041925, -0.154...    209     38  0.000   \n",
       "4  [0.05216053, 0.14466654, -0.15954311, 0.104861...    357     60  0.071   \n",
       "\n",
       "     neu    pos  compound  w_abandon  w_abatement  w_abc  ...  w_zealand  \\\n",
       "0  0.828  0.115    0.4019        0.0          0.0    0.0  ...        0.0   \n",
       "1  0.632  0.368    0.9735        0.0          0.0    0.0  ...        0.0   \n",
       "2  0.860  0.031   -0.6249        0.0          0.0    0.0  ...        0.0   \n",
       "3  1.000  0.000    0.0000        0.0          0.0    0.0  ...        0.0   \n",
       "4  0.765  0.163    0.3818        0.0          0.0    0.0  ...        0.0   \n",
       "\n",
       "   w_zeitgeist    w_zest  w_zested   w_zesty  w_zinfandel    w_zing  w_zingy  \\\n",
       "0          0.0  0.000000       0.0  0.000000          0.0  0.000000      0.0   \n",
       "1          0.0  0.000000       0.0  0.180853          0.0  0.189745      0.0   \n",
       "2          0.0  0.131935       0.0  0.000000          0.0  0.000000      0.0   \n",
       "3          0.0  0.000000       0.0  0.000000          0.0  0.000000      0.0   \n",
       "4          0.0  0.000000       0.0  0.000000          0.0  0.000000      0.0   \n",
       "\n",
       "   w_zip  w_zippy  \n",
       "0    0.0      0.0  \n",
       "1    0.0      0.0  \n",
       "2    0.0      0.0  \n",
       "3    0.0      0.0  \n",
       "4    0.0      0.0  \n",
       "\n",
       "[5 rows x 4742 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting and submission\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "def test_data_transformer(test):\n",
    "    test['lemmas'] = test.description.apply(lemmaz)\n",
    "    test['text'] = stringz(test.lemmas)\n",
    "    test['vector'] = test.text.apply(vec)\n",
    "\n",
    "    test[\"chars\"] = test.description.apply(lambda x: len(x))\n",
    "    test[\"words\"] = test.description.apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "    test[\"sentiments\"] = test.text.apply(lambda x: sid.polarity_scores(x))\n",
    "    test = pd.concat([test.drop(['sentiments'], axis=1),\n",
    "                      test['sentiments'].apply(pd.Series)], axis=1)\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_result = tfidf.fit_transform(test.text).toarray()\n",
    "    tfidf_df = pd.DataFrame(tfidf_result, columns=tfidf.get_feature_names())\n",
    "    tfidf_df.columns = [\"w_\" + str(x) for x in tfidf_df.columns]\n",
    "    tfidf_df.index = test.index\n",
    "\n",
    "    test_ready = pd.concat(\n",
    "        [test.drop(columns=['description', 'lemmas', 'text', 'id']), tfidf_df], axis=1)\n",
    "    \n",
    "    return test_ready\n",
    "\n",
    "test_ready = test_data_transformer(test)\n",
    "# prediction = tuned_rscv.predict(test_ready)\n",
    "# submission = pd.DataFrame({'id': test_ready.id, 'ratingCategory': prediction})\n",
    "# submission.to_csv('submission2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
